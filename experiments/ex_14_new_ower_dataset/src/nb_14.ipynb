{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Mar 11\n",
    "\n",
    "Build OWER datasets with more sentences. In fact, include all Ryn sentences\n",
    "in the OWER dataset and limit the number of sentences just before training.\n",
    "The same could be done for classes.\n",
    "\n",
    "Also, include the classes, debug information like entity names and other\n",
    "information from the Ryn dataset that is later required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "from typing import List, Tuple, Dict, Set\n",
    "\n",
    "from IPython.core.display import display\n",
    "from pandas import DataFrame\n",
    "\n",
    "from dao.ower.ower_dir import OwerDir\n",
    "from dao.ryn.ryn_dir import RynDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ryn_dir_path = '../data/ryn/irt.fb.irt.30.clean'\n",
    "ower_dir_path = '../data/ower/ower-fb-irt'\n",
    "class_count = 8\n",
    "sent_count = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Load Triples TXTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ryn_dir = RynDir('Ryn Directory', Path(ryn_dir_path))\n",
    "ryn_dir.check()\n",
    "\n",
    "split_dir = ryn_dir.split_dir\n",
    "cw_train_triples: List[Tuple[int, int, int]] = split_dir.cw_train_triples_txt.load_triples()\n",
    "cw_valid_triples: List[Tuple[int, int, int]] = split_dir.cw_valid_triples_txt.load_triples()\n",
    "ow_valid_triples: List[Tuple[int, int, int]] = split_dir.ow_valid_triples_txt.load_triples()\n",
    "ow_test_triples: List[Tuple[int, int, int]] = split_dir.ow_test_triples_txt.load_triples()\n",
    "\n",
    "train_triples = cw_train_triples + cw_valid_triples\n",
    "valid_triples = ow_valid_triples\n",
    "test_triples = ow_test_triples\n",
    "\n",
    "display('train_triples', len(train_triples), train_triples[:4])\n",
    "display('valid_triples', len(valid_triples), valid_triples[:4])\n",
    "display('test_triples', len(test_triples), test_triples[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ent_to_label = ryn_dir.split_dir.entity_labels_txt.load()\n",
    "rel_to_label = ryn_dir.split_dir.relation_labels_txt.load()\n",
    "\n",
    "df_cols = ['head', 'rel', 'tail']\n",
    "\n",
    "df_data = ((ent_to_label[head], rel_to_label[rel], ent_to_label[tail]) for head, rel, tail in train_triples)\n",
    "df = DataFrame(data=df_data, columns=df_cols)\n",
    "display(df)\n",
    "\n",
    "df_data = ((ent_to_label[head], rel_to_label[rel], ent_to_label[tail]) for head, rel, tail in valid_triples)\n",
    "df = DataFrame(data=df_data, columns=df_cols)\n",
    "display(df)\n",
    "\n",
    "df_data = ((ent_to_label[head], rel_to_label[rel], ent_to_label[tail]) for head, rel, tail in test_triples)\n",
    "df = DataFrame(data=df_data, columns=df_cols)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Save triples to Triples DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ower_dir = OwerDir('OWER Directory', Path(ower_dir_path))\n",
    "ower_dir.create()\n",
    "\n",
    "train_triples_db = ower_dir.tmp_dir.train_triples_db\n",
    "train_triples_db.create_triples_table()\n",
    "train_triples_db.insert_triples(train_triples)\n",
    "\n",
    "valid_triples_db = ower_dir.tmp_dir.valid_triples_db\n",
    "valid_triples_db.create_triples_table()\n",
    "valid_triples_db.insert_triples(valid_triples)\n",
    "\n",
    "test_triples_db = ower_dir.tmp_dir.test_triples_db\n",
    "test_triples_db.create_triples_table()\n",
    "test_triples_db.insert_triples(test_triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Copy Ryn Label TXTs to OWER Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "copyfile(ryn_dir.split_dir.entity_labels_txt._path, ower_dir.ent_labels_txt._path)\n",
    "copyfile(ryn_dir.split_dir.relation_labels_txt._path, ower_dir.rel_labels_txt._path)\n",
    "\n",
    "ent_to_label = ower_dir.ent_labels_txt.load()\n",
    "rel_to_label = ower_dir.rel_labels_txt.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Query most common classes and write them to Classes TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rel_tail_supps = train_triples_db.select_top_rel_tails(class_count)\n",
    "\n",
    "rel_tail_supps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ent_count = len(ent_to_label)\n",
    "\n",
    "rel_tail_freq_labels = [(rel, tail, supp / ent_count, f'{rel_to_label[rel]} {ent_to_label[tail]}')\n",
    "                        for rel, tail, supp in rel_tail_supps]\n",
    "\n",
    "ower_dir.classes_tsv.save(rel_tail_freq_labels)\n",
    "\n",
    "rel_tail_freq_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Query classes' entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_class_ents = []\n",
    "valid_class_ents = []\n",
    "test_class_ents = []\n",
    "\n",
    "for rel, tail, _ in rel_tail_supps:\n",
    "    class_ents = ower_dir.tmp_dir.train_triples_db.select_heads_with_rel_tail(rel, tail)\n",
    "    train_class_ents.append(class_ents)\n",
    "\n",
    "for rel, tail, _ in rel_tail_supps:\n",
    "    class_ents = ower_dir.tmp_dir.valid_triples_db.select_heads_with_rel_tail(rel, tail)\n",
    "    valid_class_ents.append(class_ents)\n",
    "    \n",
    "for rel, tail, _ in rel_tail_supps:\n",
    "    class_ents = ower_dir.tmp_dir.test_triples_db.select_heads_with_rel_tail(rel, tail)\n",
    "    test_class_ents.append(class_ents)\n",
    "\n",
    "display('train, class 0:', len(train_class_ents[0]), list(train_class_ents[0])[:10])\n",
    "display('valid, class 0:', len(valid_class_ents[0]), list(valid_class_ents[0])[:10])\n",
    "display('test, class 0:', len(test_class_ents[0]), list(test_class_ents[0])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Create OWER Sample TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ent_to_sents: Dict[int, Set[str]] = ryn_dir.text_dir.cw_train_sentences_txt.load()\n",
    "valid_ent_to_sents: Dict[int, Set[str]] = ryn_dir.text_dir.ow_valid_sentences_txt.load()\n",
    "test_ent_to_sents: Dict[int, Set[str]] = ryn_dir.text_dir.ow_test_sentences_txt.load()\n",
    "\n",
    "def get_samples(ent_to_sents, class_ents):\n",
    "    \"\"\"\n",
    "    :param ent_to_sents: {ent: {sent}}\n",
    "    :param class_ents: [[ent]]\n",
    "    :return: [(ent, label, [has class], [sent])\n",
    "    \"\"\"\n",
    "\n",
    "    ent_lbl_classes_sents_list = []\n",
    "    \n",
    "    for ent, sents in ent_to_sents.items():\n",
    "        \n",
    "        ent_classes = []\n",
    "        for class_ in range(len(class_ents)):\n",
    "            ent_classes.append(int(ent in class_ents[class_]))\n",
    "        \n",
    "        if len(sents) < sent_count:\n",
    "            logging.warning(f\"Entity '{ent_to_label[ent]}' ({ent}) has less than {sent_count} sentences. Skipping\")\n",
    "            continue\n",
    "        \n",
    "        ent_lbl_classes_sents_list.append((ent, ent_to_label[ent], ent_classes, sents))\n",
    "    \n",
    "    return ent_lbl_classes_sents_list\n",
    "\n",
    "train_samples = get_samples(train_ent_to_sents, train_class_ents)\n",
    "valid_samples = get_samples(valid_ent_to_sents, valid_class_ents)\n",
    "test_samples = get_samples(test_ent_to_sents, test_class_ents)\n",
    "\n",
    "ower_dir.train_samples_tsv.save(train_samples)\n",
    "ower_dir.valid_samples_tsv.save(valid_samples)\n",
    "ower_dir.test_samples_tsv.save(test_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}