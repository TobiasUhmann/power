{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feb 25\n",
    "\n",
    "For some reason the valid loss does not decrease significantly\n",
    "on the attention model. Compare with a baseline that does not\n",
    "include the attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from IPython.lib.pretty import pretty\n",
    "from torch import tensor\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from notebooks._05_no_attention import util\n",
    "from notebooks._05_no_attention.classifier import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Define train/valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "util.batch_size = batch_size = 2\n",
    "util.class_count = class_count = 3\n",
    "util.emb_size = emb_size = 4\n",
    "util.sent_count = sent_count = 3\n",
    "util.sent_len = sent_len = 3\n",
    "\n",
    "train_data = [\n",
    "    {\n",
    "        'classes': [1, 1, 1],\n",
    "        'sents': [\n",
    "            'married married married',\n",
    "            'male male male',\n",
    "            'American American American'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'classes': [0, 0, 0],\n",
    "        'sents': [\n",
    "            'single single single',\n",
    "            'female female female',\n",
    "            'German German German'\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "valid_data = [\n",
    "    {\n",
    "        'classes': [1, 1, 1],  # married, male, American\n",
    "        'sents': [\n",
    "            'Barack is married',\n",
    "            'Barack is male',\n",
    "            'Barack is American'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'classes': [1, 0, 0],  # married, male, American\n",
    "        'sents': [\n",
    "            'Angela is married',\n",
    "            'Angela is female',\n",
    "            'Angela is German'\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Pre-processing\n",
    "\n",
    "## 2.1 Build vocabulary from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "train_words = [word for ent in train_data for sent in ent['sents'] for word in tokenize(sent)]\n",
    "vocab = Vocab(Counter(train_words))\n",
    "\n",
    "print(pretty(vocab.stoi))\n",
    "\n",
    "util.vocab = vocab\n",
    "util.vocab_size = vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Transform train/valid data\n",
    "\n",
    "Map words to tokens and create tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_sents_batch = tensor([[[vocab[word] for word in tokenize(sent)] for sent in ent['sents']] for ent in train_data])\n",
    "train_classes_batch = torch.tensor([ent['classes'] for ent in train_data])\n",
    "\n",
    "valid_sents_batch = tensor([[[vocab[word] for word in tokenize(sent)] for sent in ent['sents']] for ent in valid_data])\n",
    "valid_classes_batch = torch.tensor([ent['classes'] for ent in valid_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3 Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier = Classifier(vocab_size, emb_size, class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# criterion = MSELoss()\n",
    "criterion = BCEWithLogitsLoss()\n",
    "# criterion = BCEWithLogitsLoss(pos_weight=torch.tensor([80] * class_count))\n",
    "\n",
    "# optimizer = SGD(classifier.parameters(), lr=0.1)\n",
    "optimizer = Adam(classifier.parameters(), lr=0.1)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "for epoch in range(1000):\n",
    "\n",
    "    #\n",
    "    # Train\n",
    "    #\n",
    "\n",
    "    train_logits_batch = classifier(train_sents_batch)\n",
    "    train_loss = criterion(train_logits_batch, train_classes_batch.float())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #\n",
    "    # Validate\n",
    "    #\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_logits_batch = classifier(valid_sents_batch)\n",
    "        valid_loss = criterion(valid_logits_batch, valid_classes_batch.float())\n",
    "\n",
    "    #\n",
    "    # Log\n",
    "    #\n",
    "\n",
    "    writer.add_scalars('loss', {'train': train_loss, 'valid': valid_loss}, epoch)\n",
    "\n",
    "    if epoch in [0, 9, 99, 999]:\n",
    "        print(f'Epoch {epoch}: Train loss = {train_loss.item()}, valid loss = {valid_loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5 Test\n",
    "\n",
    "## 5.1 Define test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        'classes': [1, 0, 1],  # married, male, American\n",
    "        'sents': [\n",
    "            'Michelle is married',\n",
    "            'Michelle is female',\n",
    "            'Michelle is American'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'classes': [1, 0, 0],  # married, male, American\n",
    "        'sents': [\n",
    "            'Angela is married',\n",
    "            'Angela is female',\n",
    "            'Angela is German'\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Pre-process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_sents_batch = tensor([[[vocab[word] for word in tokenize(sent)] for sent in ent['sents']] for ent in test_data])\n",
    "test_classes_batch = torch.tensor([ent['classes'] for ent in test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Forward test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_logits_batch = classifier(test_sents_batch)\n",
    "test_loss = criterion(test_logits_batch, test_classes_batch.float())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}