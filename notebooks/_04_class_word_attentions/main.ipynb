{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feb 24\n",
    "\n",
    "The training in notebook _03_overfit_and_test seems to work. The classifier\n",
    "overfits on the training data and correctly predicts when given the training\n",
    "data for testing.\n",
    "\n",
    "Now, the classifier code should be enhanced to a PyTorch module that is trained\n",
    "in a training + validation loop as it is the case in the code base. The loss\n",
    "curve should be printed as well.\n",
    "\n",
    "The expected result is a loss curve similar to the one resulting from the code\n",
    "base, i.e. validation loss should drop until around the 5th epoch after which\n",
    "it should rise again\n",
    "\n",
    "Hopefully, this notebook provides the means to debug and understand why the\n",
    "validation loss curve does not drop further and thus, why the classifier does\n",
    "not yield better test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from IPython.lib.pretty import pretty\n",
    "from torch import tensor\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from notebooks._04_class_word_attentions import util\n",
    "from notebooks._04_class_word_attentions.classifier import Classifier\n",
    "from notebooks._04_class_word_attentions.util import log_tensor, get_ent_lbls, get_sent_lbls, get_tok_lbls, \\\n",
    "    get_emb_lbls, get_class_lbls, get_mix_emb_lbls, get_word_lbls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Define train/valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "util.batch_size = batch_size = 2\n",
    "util.class_count = class_count = 3\n",
    "util.emb_size = emb_size = 4\n",
    "util.sent_count = sent_count = 3\n",
    "util.sent_len = sent_len = 3\n",
    "\n",
    "train_data = [\n",
    "    {\n",
    "        'classes': [1, 1, 1],\n",
    "        'sents': [\n",
    "            'married married married',\n",
    "            'male male male',\n",
    "            'American American American'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'classes': [0, 0, 0],\n",
    "        'sents': [\n",
    "            'single single single',\n",
    "            'female female female',\n",
    "            'German German German'\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "valid_data = [\n",
    "    {\n",
    "        'classes': [1, 1, 1],  # married, male, American\n",
    "        'sents': [\n",
    "            'Barack is married',\n",
    "            'Barack is male',\n",
    "            'Barack is American'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'classes': [1, 0, 0],  # married, male, American\n",
    "        'sents': [\n",
    "            'Angela is married',\n",
    "            'Angela is female',\n",
    "            'Angela is German'\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Pre-processing\n",
    "\n",
    "## 2.1 Build vocabulary from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "train_words = [word for ent in train_data for sent in ent['sents'] for word in tokenize(sent)]\n",
    "vocab = Vocab(Counter(train_words))\n",
    "\n",
    "print(pretty(vocab.stoi))\n",
    "\n",
    "util.vocab = vocab\n",
    "util.vocab_size = vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Transform train/valid data\n",
    "\n",
    "Map words to tokens and create tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_sents_batch = tensor([[[vocab[word] for word in tokenize(sent)] for sent in ent['sents']] for ent in train_data])\n",
    "train_classes_batch = torch.tensor([ent['classes'] for ent in train_data])\n",
    "\n",
    "valid_sents_batch = tensor([[[vocab[word] for word in tokenize(sent)] for sent in ent['sents']] for ent in valid_data])\n",
    "valid_classes_batch = torch.tensor([ent['classes'] for ent in valid_data])\n",
    "\n",
    "log_tensor(train_sents_batch, 'train_sents_batch', [get_ent_lbls(), get_sent_lbls(), get_tok_lbls()])\n",
    "log_tensor(valid_sents_batch, 'valid_sents_batch', [get_ent_lbls(), get_sent_lbls(), get_tok_lbls()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3 Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = Classifier(vocab_size, emb_size, class_count)\n",
    "\n",
    "log_tensor(classifier.embedding_bag.weight.detach(), 'classifier.embedding_bag.weight', [get_word_lbls(), get_emb_lbls()])\n",
    "log_tensor(classifier.class_embs.detach(), 'classifier.class_embs', [get_class_lbls(), get_emb_lbls()])\n",
    "log_tensor(classifier.linear.weight.data.detach(), 'classifier.linear.weight.data', [get_class_lbls(), get_mix_emb_lbls()])\n",
    "log_tensor(classifier.linear.bias.data.detach(), 'classifier.linear.bias.data', [get_class_lbls()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# criterion = MSELoss()\n",
    "criterion = BCEWithLogitsLoss()\n",
    "# criterion = BCEWithLogitsLoss(pos_weight=torch.tensor([80] * class_count))\n",
    "\n",
    "# optimizer = SGD(classifier.parameters(), lr=0.1)\n",
    "optimizer = Adam(classifier.parameters(), lr=0.1)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "for epoch in range(1000):\n",
    "\n",
    "    #\n",
    "    # Train\n",
    "    #\n",
    "\n",
    "    train_logits_batch = classifier(train_sents_batch)\n",
    "    train_loss = criterion(train_logits_batch, train_classes_batch.float())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #\n",
    "    # Validate\n",
    "    #\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_logits_batch = classifier(valid_sents_batch)\n",
    "        valid_loss = criterion(valid_logits_batch, valid_classes_batch.float())\n",
    "\n",
    "    #\n",
    "    # Log\n",
    "    #\n",
    "\n",
    "    writer.add_scalars('loss', {'train': train_loss, 'valid': valid_loss}, epoch)\n",
    "\n",
    "    if epoch in [0, 9, 99, 999]:\n",
    "        print(f'Epoch {epoch}: Train loss = {train_loss.item()}, valid loss = {valid_loss.item()}')\n",
    "\n",
    "        # log_tensor(classifier.embedding_bag.weight.detach(), 'classifier.embedding_bag.weight', [get_word_lbls(), get_emb_lbls()])\n",
    "        # log_tensor(classifier.class_embs.detach(), 'classifier.class_embs', [get_class_lbls(), get_emb_lbls()])\n",
    "        # log_tensor(classifier.linear.weight.data.detach(), 'classifier.linear.weight.data', [get_class_lbls(), get_mix_emb_lbls()])\n",
    "        # log_tensor(classifier.linear.bias.data.detach(), 'classifier.linear.bias.data', [get_class_lbls()])\n",
    "        #\n",
    "        # log_tensor(train_logits_batch.detach(), 'train_logits_batch', [get_ent_lbls(), get_class_lbls()])\n",
    "        # log_tensor(train_classes_batch.detach(), 'train_classes_batch', [get_ent_lbls(), get_class_lbls()])\n",
    "        #\n",
    "        # log_tensor(valid_logits_batch.detach(), 'valid_logits_batch', [get_ent_lbls(), get_class_lbls()])\n",
    "        # log_tensor(valid_classes_batch.detach(), 'valid_classes_batch', [get_ent_lbls(), get_class_lbls()])\n",
    "\n",
    "        #\n",
    "        # How well do class embeddings match words?\n",
    "        #\n",
    "\n",
    "        class_embs = classifier.class_embs.data.detach()\n",
    "        tok_embs = classifier.embedding_bag.weight.detach()\n",
    "\n",
    "        atts_batch = torch.mm(class_embs, tok_embs.T)\n",
    "        log_tensor(atts_batch, 'atts_batch', [get_class_lbls(), get_word_lbls()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5 Test\n",
    "\n",
    "## 5.1 Define test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        'classes': [1, 0, 1],  # married, male, American\n",
    "        'sents': [\n",
    "            'Michelle is married',\n",
    "            'Michelle is female',\n",
    "            'Michelle is American'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'classes': [1, 0, 0],  # married, male, American\n",
    "        'sents': [\n",
    "            'Angela is married',\n",
    "            'Angela is female',\n",
    "            'Angela is German'\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Pre-process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_sents_batch = tensor([[[vocab[word] for word in tokenize(sent)] for sent in ent['sents']] for ent in test_data])\n",
    "test_classes_batch = torch.tensor([ent['classes'] for ent in test_data])\n",
    "\n",
    "log_tensor(test_sents_batch, 'test_sents_batch', [get_ent_lbls(), get_sent_lbls(), get_tok_lbls()])\n",
    "log_tensor(test_classes_batch, 'test_classes_batch', [get_ent_lbls(), get_class_lbls()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Forward test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_logits_batch = classifier(test_sents_batch)\n",
    "test_loss = criterion(test_logits_batch, test_classes_batch.float())\n",
    "\n",
    "log_tensor(test_logits_batch, 'test_logits_batch', [get_ent_lbls(), get_class_lbls()])\n",
    "log_tensor(test_classes_batch, 'test_classes_batch', [get_ent_lbls(), get_class_lbls()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}