{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from util import log_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "channel_size = 3\n",
    "batch_size = 2\n",
    "input_size = 4\n",
    "output_size = 2\n",
    "\n",
    "channel_lbls = [f'channel {i}' for i in range(channel_size)]\n",
    "ent_lbls = [f'ent {i}' for i in range(batch_size)]\n",
    "emb_lbls = [f'emb {i}' for i in range(input_size)]\n",
    "class_lbls = [f'class {i}' for i in range(output_size)]\n",
    "\n",
    "my_tensor = torch.randn(batch_size, channel_size, input_size)\n",
    "log_tensor(my_tensor, 'my_tensor', [ent_lbls, channel_lbls, emb_lbls])\n",
    "\n",
    "weight = torch.randn(channel_size, input_size, output_size)\n",
    "log_tensor(weight, 'weight', [channel_lbls, emb_lbls, class_lbls])\n",
    "\n",
    "bias = torch.randn(channel_size, 1, output_size)\n",
    "log_tensor(bias, 'bias', [channel_lbls, [''], class_lbls])\n",
    "\n",
    "output = torch.bmm(my_tensor.transpose(0, 1), weight) + bias\n",
    "log_tensor(output, 'output', [channel_lbls, ent_lbls, class_lbls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "class_count = 3\n",
    "emb_size = 4\n",
    "out_count = 2\n",
    "\n",
    "ent_lbls = [f'ent {i}' for i in range(batch_size)]\n",
    "class_lbls = [f'class {i}' for i in range(class_count)]\n",
    "emb_lbls = [f'emb {i}' for i in range(emb_size)]\n",
    "out_lbls = [f'out {i}' for i in range(2)]\n",
    "\n",
    "# (batch_size, class_count, emb_size)\n",
    "mixes_batch = torch.tensor([\n",
    "    [[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.]],\n",
    "    [[-1., 0., 0., 0.], [0., -1., 0., 0.], [0., 0., -1., 0.]]\n",
    "])\n",
    "# mixes_batch = torch.randn(batch_size, class_count, emb_size)\n",
    "log_tensor(mixes_batch, 'mixes_batch', [ent_lbls, class_lbls, emb_lbls])\n",
    "\n",
    "weight = torch.randn(class_count, emb_size, out_count, requires_grad=True)\n",
    "log_tensor(weight, 'weight', [class_lbls, emb_lbls, out_lbls])\n",
    "\n",
    "bias = torch.randn(class_count, 1, out_count, requires_grad=True)\n",
    "log_tensor(bias, 'bias', [class_lbls, [''], out_lbls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam([weight, bias], lr=0.1)\n",
    "\n",
    "gt0 = torch.tensor([\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "\n",
    "# gt = torch.tensor([\n",
    "#     [[0, 1], [0, 1], [0, 1]],\n",
    "#     [[1, 0], [1, 0], [1, 0]]\n",
    "# ])\n",
    "gt = torch.nn.functional.one_hot(gt0)\n",
    "\n",
    "for epoch in range(20):\n",
    "    print(f'Epoch {epoch}')\n",
    "\n",
    "    logits = torch.bmm(mixes_batch.transpose(0, 1), weight) + bias\n",
    "    logits = logits.transpose(0, 1)\n",
    "    # log_tensor(logits, 'logits', [ent_lbls, class_lbls, out_lbls])\n",
    "\n",
    "    softs = torch.nn.Softmax(dim=-1)(logits)\n",
    "    log_tensor(softs, 'softs', [ent_lbls, class_lbls, out_lbls])\n",
    "\n",
    "    log_tensor(gt, 'gt', [ent_lbls, class_lbls, out_lbls])\n",
    "\n",
    "    loss = criterion(logits, gt.float())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target = torch.randint(0, 10, (10,))\n",
    "one_hot = torch.nn.functional.one_hot(target)\n",
    "\n",
    "print(target)\n",
    "print(one_hot)\n",
    "\n",
    "gt0 = torch.tensor([\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "\n",
    "gt = torch.tensor([\n",
    "    [[0, 1], [0, 1], [0, 1]],\n",
    "    [[1, 0], [1, 0], [1, 0]]\n",
    "])\n",
    "\n",
    "torch.nn.functional.one_hot(gt0)\n",
    "torch.argmax(gt, dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}